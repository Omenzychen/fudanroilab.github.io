---
title:  'RPATTACK: Refined Patch Attack on General Object Detectors'  #  Paper title, covered by ''
teser: huang2021.png
type:   paper
pro_type: Visual Place Recognition
layout: post  #  Do not change this
date:   2021-03-23 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Hao Huang, Yongtao Wang, Zhaoyu Chen, Zhi Tang, Wenqiang Zhang, Kai-Kuang Ma  # authors information
venue:  IEEE International Conference on Multimedia and Expo (ICME 2021) (CCF B) # Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2021  # paper year, number
month:  March  # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: https://github.com/VDIGPKU/RPAttack  # If has data, post code link here, otherwise None
paperLink: https://arxiv.org/abs/2103.12469 # post paper pdf link here
---

Nowadays, general object detectors like YOLO and Faster R-CNN as well as their variants are widely exploited in many applications. Many works have revealed that these detectors are extremely vulnerable to adversarial patch attacks. The perturbed regions generated by previous patch-based attack works on object detectors are very large which are not necessary for attacking and perceptible for human eyes. To generate much less but more efficient perturbation, we propose a novel patch-based method for attacking general object detectors. Firstly, we propose a patch selection and refining scheme to find the pixels which have the greatest importance for attack and remove the inconsequential perturbations gradually. Then, for a stable ensemble attack, we balance the gradients of detectors to avoid over-optimizing one of them during the training phase. Our RPAttack can achieve an amazing missed detection rate of 100% for both Yolo v4 and Faster R-CNN while only modifies 0.32% pixels on VOC 2007 test set.