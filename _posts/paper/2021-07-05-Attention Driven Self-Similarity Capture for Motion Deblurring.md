---
title:  'Attention Driven Self-Similarity Capture for Motion Deblurring'  #  Paper title, covered by ''
teser: 2021zhangicme.gif
type:   paper
pro_type: Visual Place Recognition
layout: post  #  Do not change this
date:   2021-07-05 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Jie Zhang，Chuanfa Zhang，Jiangzhou Wang，Qingyue Xiong，Wenqiang Zhang  # authors information
venue:  IEEE International Conference on Multimedia and Expo (ICME 2021) (CCF B) # Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2021  # paper year, number
month:  July  # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: None  # If has data, post code link here, otherwise None
paperLink: https://ieeexplore.ieee.org/document/9428104/ # post paper pdf link here
---

Recently, deep learning-based algorithms have brought impressive results in deblurring tasks. However, as an image prior proved important in image restoration tasks, self-similarity was not exploited in motion deblurring. To tackle this problem, we propose an Attention Self-Similarity Capture (ASSC) module, which takes full advantage of self-similarity by capturing long-range feature dependencies. Besides, to achieve a trade-off between performance and efficiency, we design an Enhanced Spatial Attention (ESA) module, which can dynamically adapt to the spatially-varying motion blur. We employ patch-hierarchical architecture composed of the two modules mentioned above with parameter-free feature flow between different levels. Moreover, we build two large-scale datasets, GOPRO-Supplement and SONY-Extension, to expand the public GOPRO dataset’s scene and resolution. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on both the public GOPRO dataset and our datasets.